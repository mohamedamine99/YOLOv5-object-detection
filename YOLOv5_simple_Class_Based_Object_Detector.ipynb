{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "# YOLOv5 simple object detector using a class-based approach\n",
        "\n",
        "</div>\n",
        "\n",
        "The YOLOv5 is a powerful object detection algorithm that combines high accuracy and real-time detection speeds. This Colab notebook demonstrates how to implement a simple object detector using a class-based approach, allowing us to detect objects in both static images and videos.\n",
        "\n",
        "By using a class-based approach, the notebook will offer several advantages over other approaches, such as easier maintenance and extensibility of the code. The code will also be more modular and easier to understand, making it accessible to a wider audience of users.\n"
      ],
      "metadata": {
        "id": "__RRUqeCJo-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries, modules and files"
      ],
      "metadata": {
        "id": "ZoZrnFsqLDR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### importing files from my github repo"
      ],
      "metadata": {
        "id": "wwFSZL50YWFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mohamedamine99/YOLOv5-object-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_FEoVtf-igA",
        "outputId": "2161ed61-3fcc-4bb3-9698-a2a3075b8751"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLOv5-object-detection'...\n",
            "remote: Enumerating objects: 226, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 226 (delta 11), reused 42 (delta 6), pack-reused 174\u001b[K\n",
            "Receiving objects: 100% (226/226), 435.02 MiB | 26.83 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n",
            "Updating files: 100% (93/93), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### importing modules"
      ],
      "metadata": {
        "id": "7ywW_Y4qYmI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import random\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
        "import torch"
      ],
      "metadata": {
        "id": "Csdrs23IAvFJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2aZwji-vloL",
        "outputId": "eae915d1-2ae9-4e42-a8d2-3258b01e2172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.54 🚀 Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 26.3/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics  # install\n",
        "import ultralytics\n",
        "ultralytics.checks()  # checks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Yolov5_ObjectDetector class\n",
        "\n",
        "**Description:** This code defines a YOLOv5_ObjectDetector \n",
        "class that performs object detection on images and videos using the YOLOv5 deep learning model. The class constructor takes as input the YOLOv5 model name, labels, colors, confidence threshold, IOU threshold, number of classes, and maximum number of detections. It initializes the model using the torch.hub.load function from the Ultralytics repository. The class has methods to run object detection on images and videos, print detection results, print detections on images, and save detection results to disk."
      ],
      "metadata": {
        "id": "o-lyB1kUYQzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Yolov5_ObjectDetector:\n",
        "    def __init__(self, model_name, labels, colors,\n",
        "                 conf=0.25, iou=0.45,\n",
        "                 classes=None, max_det=1000):\n",
        "        # constructor code here\n",
        "        self.model = torch.hub.load('ultralytics/yolov5', model_name, force_reload=True, verbose = False)\n",
        "        self.colors = colors\n",
        "        self.model_name = model_name\n",
        "        self.labels = labels\n",
        "        self.model.conf = conf\n",
        "        self.model.iou = iou\n",
        "        self.model.classes = classes\n",
        "        self.model.max_det = max_det\n",
        "\n",
        "    \n",
        "    def print_results(self, results):\n",
        "        \n",
        "        # get the list of labels present in the results vector\n",
        "        labels_list = [self.labels[int(r[5])] for r in results]\n",
        "        # count the occurences of each label\n",
        "        counter_dict = Counter(labels_list)\n",
        "        #print(results)\n",
        "        print(f\"model : {self.model_name}\")\n",
        "        print(\"Detected objects : \", end = '')\n",
        "        for key in counter_dict.keys():\n",
        "            print(f\"{key} : {counter_dict[key]} \" , end = ' ')\n",
        "        \n",
        "        print()\n",
        "        #print(counter_dict)\n",
        "\n",
        "\n",
        "    def run_img_detection(self, img : np.ndarray, verbose = True):\n",
        "        if img.ndim != 3 or img.shape[2]!=3 :\n",
        "            raise ValueError(\"input img should be a 3-dimensional numpy array with 3 colors\")\n",
        "\n",
        "        results = self.model(img)\n",
        "        results = np.array(results.xyxy[0])\n",
        "        if verbose :\n",
        "            print(\"----------------------------\")\n",
        "        \n",
        "            print(f\"image shape : {img.shape}\")\n",
        "            self.print_results(results)\n",
        "\n",
        "        return(results)\n",
        "\n",
        "    \n",
        "    def run_img_detection_from_path(self, img_path, verbose = True):\n",
        "        if not os.path.exists(img_path):\n",
        "            raise ValueError(f\"File path {img_path} does not exist.\")\n",
        "        \n",
        "        img = cv2.imread(img_path)\n",
        "        img_name = os.path.basename(img_path)\n",
        "\n",
        "        if verbose : \n",
        "            print(\"\\n----------------------------\")\n",
        "            print(f\"{img_name} :\")\n",
        "\n",
        "        results = self.run_img_detection(img, verbose)        \n",
        "        return (results)\n",
        "\n",
        "\n",
        "    def print_detections_on_image(self, detections: np.ndarray, img: np.ndarray):\n",
        "        if img.ndim != 3 :\n",
        "            raise ValueError(\"input img should be a 3-dimensional numpy array\")\n",
        "\n",
        "        # calculate the bounding box thickness based on the image width and height\n",
        "        bbx_thickness = (img.shape[0] + img.shape[1]) // 500\n",
        "\n",
        "        for r in detections:\n",
        "            # Extract object class and confidence score\n",
        "            score = r[4] * 100\n",
        "            r = r.astype(int)\n",
        "            class_id = r[5]\n",
        "\n",
        "            # Calculate font scale based on object size\n",
        "            fontScale = (((r[2] - r[0]) / img.shape[0]) + ((r[3] - r[1]) / img.shape[1])) / 2 * 1.5\n",
        "\n",
        "            # Draw bounding box, a centroid and label on the image\n",
        "            im = cv2.putText(img,f\"{self.labels[class_id]} {score:,.2f}%\" , \n",
        "                            (r[0],r[1] - 5), cv2.FONT_HERSHEY_COMPLEX, \n",
        "                        fontScale,  self.colors[class_id], 1, cv2.LINE_AA)\n",
        "            \n",
        "            im = cv2.rectangle(im, (r[0],r[1]), (r[2],r[3]), self.colors[class_id], bbx_thickness)\n",
        "\n",
        "            center_coordinates = ((r[2] + r[0])//2, (r[3] + r[1]) // 2)\n",
        "            im =  cv2.circle(im, center_coordinates, 2 , (0,0,255), -1)\n",
        "\n",
        "        return im\n",
        "\n",
        "\n",
        "\n",
        "    def save_img_detection(self, img, save_dir, file_name ):\n",
        "\n",
        "        if not os.path.exists(save_dir):\n",
        "            raise ValueError(f\"File path {save_dir} does not exist.\")\n",
        "\n",
        "        # save resulting images in their corresponding folders\n",
        "        save_file = os.path.join(save_dir, self.model_name, file_name)\n",
        "        print(f\"Saving Detection Results of {file_name} to {save_file}\")\n",
        "        cv2.imwrite(save_file ,img)\n",
        "        \n",
        "        \n",
        "\n",
        "        \n",
        "    \n",
        "    def run_multiple_imgs_detection_from_path(self, images_path, save_dir):\n",
        "    \n",
        "        for img_name in os.listdir(images_path):\n",
        "            img_path = os.path.join(images_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            results = self.run_img_detection_from_path(img_path)\n",
        "            img = self.print_detections_on_image(results, img)\n",
        "            self.save_img_detection(img, save_dir, img_name)\n",
        "\n",
        "    def run_video_detection_from_path(self, video_path, save_dir, output_FPS = 15, \n",
        "                                      output_format = '.avi', verbose = False):\n",
        "        \n",
        "        if not os.path.exists(video_path):\n",
        "            raise ValueError(f\"File path {video_path} does not exist.\")\n",
        "        \n",
        "       # Open input video file\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        print(\"\\n----------------------------\")\n",
        "\n",
        "        # Get video name \n",
        "        vid_name = os.path.basename(video_path)\n",
        "        print(vid_name, end = ' : ')\n",
        "\n",
        "        # Get frame dimensions and print information about input video file\n",
        "        width  = int(cap.get(3) )  # get `width` \n",
        "        height = int(cap.get(4) )  # get `height` \n",
        "        print((width,height))\n",
        "        print(video_path)\n",
        "        print(self.model_name)\n",
        "\n",
        "        # Set bounding box thickness based on video dimensions\n",
        "        bbx_thickness = (height + width) // 500\n",
        "\n",
        "        # Define output video file\n",
        "        save_file = os.path.join(save_dir, vid_name[:-4] + output_format)\n",
        "        print('saving to :' + save_file)\n",
        "\n",
        "        # define an output VideoWriter  object\n",
        "        out = cv2.VideoWriter(save_file,\n",
        "                            cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
        "                            output_FPS,(width,height))\n",
        "\n",
        "        # Check if the video is opened correctly\n",
        "        if not cap.isOpened():\n",
        "            print(\"Error opening video stream or file\")\n",
        "\n",
        "        # Read the video frames\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            # If the frame was not read successfully, break the loop\n",
        "            if not ret:\n",
        "                print(\"Error reading frame\")\n",
        "                break\n",
        "\n",
        "            # Run object detection on the frame and calculate FPS\n",
        "            beg = time.time()\n",
        "            results = self.run_img_detection(frame, verbose= False)\n",
        "            fps = 1 / (time.time() - beg)\n",
        "\n",
        "            # Display FPS on frame\n",
        "            frame = cv2.putText(frame,f\"FPS : {fps:,.2f}\" , \n",
        "                                (5,15), cv2.FONT_HERSHEY_COMPLEX, \n",
        "                            0.5,  (0,0,255), 1, cv2.LINE_AA)\n",
        "            \n",
        "            # Display detections on frame\n",
        "            frame = self.print_detections_on_image(results, frame)\n",
        "\n",
        "            # append frame to the video file\n",
        "            out.write(frame)\n",
        "            \n",
        "            # the 'q' button is set as the\n",
        "            # quitting button you may use any\n",
        "            # desired button of your choice\n",
        "\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "\n",
        "        # After the loop release the cap \n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PmRMFWZ3fqnR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up paths, working dirs and variables"
      ],
      "metadata": {
        "id": "95AWtTWmMHkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up paths"
      ],
      "metadata": {
        "id": "Rt5-TGoOmL81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up paths and working directories\n",
        "coco_names_file = '/content/YOLOv5-object-detection/coco.names'  # Path to file containing COCO object class names\n",
        "\n",
        "results_path = '/content/results'  # Path to directory where result images will be saved\n",
        "video_results_path = '/content/video_results'  # Path to directory where result videos will be saved\n",
        "\n",
        "test_imgs_path = '/content/YOLOv5-object-detection/test imgs'  # Path to directory containing test images\n",
        "test_vids_path = '/content/YOLOv5-object-detection/test vids'  # Path to directory containing test videos\n"
      ],
      "metadata": {
        "id": "8icYnlZitmDs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### loading COCO class names "
      ],
      "metadata": {
        "id": "672GykilPs4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the COCO dataset 80 class names from the coco names file\n",
        "labels = []\n",
        "with open(coco_names_file, 'rt') as coco_file:\n",
        "    labels = coco_file.read().rstrip('\\n').rsplit('\\n')\n",
        "    \n",
        "print(labels)\n",
        "\n",
        "# generate random color for each label\n",
        "colors = []\n",
        "for _ in labels:\n",
        "    rand_tuple = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
        "    colors.append(rand_tuple)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWdB2VNGtkIG",
        "outputId": "da4ccb51-7ac2-46c1-fbc0-c65fdb6c291b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples for instanciating Yolov5_ObjectDetector and invoking its methods"
      ],
      "metadata": {
        "id": "0JYl_GC_nUCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example for loading and detecting objects with \"yolov5n\" (a YOLOv5 variants):"
      ],
      "metadata": {
        "id": "_xof1AtGP-Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detector = Yolov5_ObjectDetector('yolov5n', labels,colors)"
      ],
      "metadata": {
        "id": "R9VK7_eVGIsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = detector.run_img_detection_from_path('/content/YOLOv5-object-detection/test imgs/people crossing the street.jpg')\n",
        "img = cv2.imread('/content/YOLOv5-object-detection/test imgs/2 dogs.PNG')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRXCNvAtGpCh",
        "outputId": "e2b06064-dd38-4257-8f51-1ae32eefa8de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------\n",
            "people crossing the street.jpg :\n",
            "----------------------------\n",
            "image shape : (976, 976, 3)\n",
            "model : yolov5n\n",
            "Detected objects : person : 5  car : 8  truck : 1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run object detection on multiple images in a directory and save the results \n",
        "os.makedirs('content/results__2')\n",
        "detector.run_multiple_imgs_detection_from_path('/content/YOLOv5-object-detection/test imgs', 'content/results__2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxpouXQug7mM",
        "outputId": "81a3b05e-f6e0-4d60-873c-04136af88a12"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------\n",
            "highway.PNG :\n",
            "----------------------------\n",
            "image shape : (303, 491, 3)\n",
            "model : yolov5n\n",
            "Detected objects : car : 9  truck : 3  bus : 1  person : 1  \n",
            "Saving Detection Results of highway.PNG to content/results__2/yolov5n/highway.PNG\n",
            "\n",
            "----------------------------\n",
            "nyc street.PNG :\n",
            "----------------------------\n",
            "image shape : (333, 479, 3)\n",
            "model : yolov5n\n",
            "Detected objects : person : 14  car : 3  truck : 1  \n",
            "Saving Detection Results of nyc street.PNG to content/results__2/yolov5n/nyc street.PNG\n",
            "\n",
            "----------------------------\n",
            "2 cats.PNG :\n",
            "----------------------------\n",
            "image shape : (293, 514, 3)\n",
            "model : yolov5n\n",
            "Detected objects : cat : 2  \n",
            "Saving Detection Results of 2 cats.PNG to content/results__2/yolov5n/2 cats.PNG\n",
            "\n",
            "----------------------------\n",
            "street 2.PNG :\n",
            "----------------------------\n",
            "image shape : (259, 502, 3)\n",
            "model : yolov5n\n",
            "Detected objects : bus : 1  person : 13  car : 2  bicycle : 4  \n",
            "Saving Detection Results of street 2.PNG to content/results__2/yolov5n/street 2.PNG\n",
            "\n",
            "----------------------------\n",
            "2 dogs.PNG :\n",
            "----------------------------\n",
            "image shape : (309, 472, 3)\n",
            "model : yolov5n\n",
            "Detected objects : dog : 2  \n",
            "Saving Detection Results of 2 dogs.PNG to content/results__2/yolov5n/2 dogs.PNG\n",
            "\n",
            "----------------------------\n",
            "people crossing the street.jpg :\n",
            "----------------------------\n",
            "image shape : (976, 976, 3)\n",
            "model : yolov5n\n",
            "Detected objects : person : 5  car : 8  truck : 1  \n",
            "Saving Detection Results of people crossing the street.jpg to content/results__2/yolov5n/people crossing the street.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and using multiple YOLOv5 variants"
      ],
      "metadata": {
        "id": "OpCxiY5Ag8_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of YOLOv5 variant model names to be loaded\n",
        "yolov5_variants_names = ['yolov5n', 'yolov5s', 'yolov5m', 'yolov5l','yolov5x', \n",
        "                   'yolov5n6','yolov5s6', 'yolov5m6', 'yolov5l6','yolov5x6' ]\n",
        "\n",
        "\n",
        "detectors = []\n",
        "# Loop through the list of model names to load each model and \n",
        "# creating Directories for Results and Video Results for YOLOv5 Variants\n",
        "\n",
        "for yolo_name in yolov5_variants_names:\n",
        "    detector = Yolov5_ObjectDetector(yolo_name, labels,colors)\n",
        "    detectors.append(detector)\n",
        "\n",
        "    new_dir = os.path.join(results_path, yolo_name)\n",
        "    if os.path.isdir(new_dir):\n",
        "        print(f\"{new_dir} already exists\")\n",
        "\n",
        "    else:\n",
        "        os.makedirs(new_dir)\n",
        "\n",
        "    new_dir = os.path.join(video_results_path, yolo_name)\n",
        "    if os.path.isdir(new_dir):\n",
        "        print(f\"{new_dir} already exists\")\n",
        "\n",
        "    else:\n",
        "        os.makedirs(new_dir)\n"
      ],
      "metadata": {
        "id": "wZwaFhUzQzVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Object Detection on Images in a Directory Using YOLOv5 Variants\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y9TjjUI6T8mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run object detection on multiple images from a path using multiple variants of yolov5\n",
        "for detector in detectors:\n",
        "    detector.run_multiple_imgs_detection_from_path(test_imgs_path, results_path)"
      ],
      "metadata": {
        "id": "beDDE1_oijJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Object Detection on Videos in a Directory Using a single YOLOv5 Variant : yolov5n\n"
      ],
      "metadata": {
        "id": "_ID1-AW8UU-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detector = Yolov5_ObjectDetector('yolov5n', labels,colors)\n",
        "detector.run_video_detection_from_path('/content/YOLOv5-object-detection/test vids/traffic.mp4', \n",
        "                                       '/content/video_results' + '/' + detector.model_name , \n",
        "                                       output_FPS = 25, output_format = '.avi')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL9R2YwvqSf0",
        "outputId": "8397ad6e-821d-4d34-fa10-445023366cd4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirement \"setuptools>=65.5.1\" not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.9/dist-packages (67.6.0)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /root/.cache/torch/hub/ultralytics_yolov5_master/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 🚀 2023-3-19 Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------\n",
            "traffic.mp4 : (640, 360)\n",
            "/content/YOLOv5-object-detection/test vids/traffic.mp4\n",
            "yolov5n\n",
            "saving to :/content/video_results/yolov5n/traffic.avi\n",
            "Error reading frame\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving results"
      ],
      "metadata": {
        "id": "RzyRPF8EYe0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r results.zip /content/results"
      ],
      "metadata": {
        "id": "P59WjCKOGO0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r video_results.zip /content/video_results"
      ],
      "metadata": {
        "id": "v3lz3ZDmQ5W4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}